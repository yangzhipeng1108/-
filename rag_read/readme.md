百度最近的RAG方案比较火，我稍微研究了一下：Query拓展 + 多路召回 + Rerank + self-Critique。总体思路有点像ReAct系列的进阶版本，
其在搜索侧和答案修正侧都做了更多的一些工作来优化实际效果。
1）Query拓展：主要参考Meta的CoVe以及百川自研的Think Step-Further方法对原始用户输入的复杂问题进行拆解、拓展，挖掘用户更深层次的子问题，
借助子问题检索效果更高的特点来解决复杂问题检索质量偏差的问题。
2） 优化检索链路：
方法：稀疏检索+向量检索 + rerank模型。其中稀疏检索应该是指BM25、ES等传统检索的方法，rerank模型百川没有提到，
不确定是用大模型来做rerank还是直接训练相关rerank模型来对检索结果排序。
效果：召回率95%，对比其他开源向量模型召回率低于80%。
3) 自我反省机制self-Critique：
方法：让大模型基于 Prompt、从相关性和可用性等角度对检索回来的内容自省，进行二次查看，从中筛选出与 Prompt 最匹配、最优质的候选内容。
目的：提升检索结果的知识密度和广度，降低检索结果中的知识噪声。
https://zhuanlan.zhihu.com/p/675770700
https://zhuanlan.zhihu.com/p/658623507


提出了一种链式验证（CoVe）方法，通过该方法模型首先起草初始回答，然后计划验证问题来核实起草结果，独立回答这些问题以避免受到其他回答的影响，最终生成验证后的回答。
CoVe包含生成基准响应、计划验证、执行验证和生成最终响应
1、生成基准回复
给定一个查询，使用LLM生成回复，采用few shot提示学习来让LLM生成基础回复
2、计划验证
给定查询和基准回复，生成一个验证问题列表，以帮助自我分析原始回复中是否有任何错误。
验证问题并不是模板化的，语言模型可以自由地以任何形式提出这些问题，而且这些问题也不必与原文的措辞完全一致。
所以，在具体实现上，通过向LLM提供（回答、验证）演示的少量提示来执行此类验证规划。
3、执行验证
依次回答每个验证问题，然后对照原始回复检查答案，检查是否存在不一致或错误。有了计划中的验证问题，下一步就是回答这些问题，以评估是否存在任何幻觉。
虽然在这一过程中可以使用检索增强等技术，例如通过搜索引擎进行验证，该工作只考虑在CoVe的所有步骤中使用LLM本身，因此模型是用来检查自身工作的。
改工作研究了验证执行的几种变体，分别称为联合、两步、因子和因子+修订
4、生成最终校验回复
根据发现的不一致之处（如有），生成包含验证结果的修订回复，通过最后的few shot提示来执行。


搜索：
1、样本生成
标注的方法分为判别式，既输入 QT 问生成式模型结论，如 “都安气车到班领气车” 和 “都安汽车到班领汽车” 哪个是正确写法；
也有通过生成式大模型生成样本如 “query = 北京” 可以扩充哪些需求词。

2、离线生成式应用
通过生成式大模型进行域提取升级如 Doc 的核心句提取，以及对缺失后验数据的 Doc 补充 Click-Query，
同时也通过使用生成式大模型对原始标题进行标准化改写的方式扩充新的标题域

3、涌现能力蒸馏
生成式大模型在参数量和样本量扩大之后，涌现了一些惊人的模型能力。如何将这种大模型的能力迁移到现有的搜索排序模型中？
搜索采用集成蒸馏的思想如图 21 所示，根据不同的数据集，不同的模型 BASE 训练多个 teacher，然后通过将多个 teacher 共同蒸馏 student 的方式，
提升 student 模型的效果。由于生成式大模型和原有的 teacher 在参数量级和输入文本长度上都获得了一个极大的提高，因此能够带来蒸馏的 student 效果大幅度提升。

4、端到端生成
生成式大模型拥有巨大的参数量级进而导致较慢的推理速度，而搜索引擎往往需要在毫秒级时间内向用户返回搜索结果，因此如何将生成式大模型引入搜索引擎的在线检索系统是个难题，
但是由于生成式大模型有惊人的效果，因此端到端的模型替换原有的系统将是一个趋势。

如图 22 所示，在纠错端到端方向，通过在生成式大模型 BASE 模型之上，通过人工标注数据做为样本集，采用 SFT 对模型进行微调产出微调之后的生成式大模型。
然而此时的模型往往还有效果不佳，幻觉等方面的问题，因此通过挂载搜索结果，知识图谱库等方式对模型进行搜索增强，产出搜索增强之后的生成式大模型。

评估效果：
在搜索系统中，评估模型效果好坏的一个重要指标是 Query-Doc 的相关性正逆序比。计算方法是根据排出的结果进行从前到后两两组对，
如果排在前面的结果比排在后面的结果更相关则是一个正序对，反之则为逆序对。正序对 / 逆序对为正逆序比，值越大越好。
如图 23 所示，在 TOP350 条结果采样正逆序比从基线 2.5 优化提升到 4.0。


Alibi 位置编码的外推性比旋转位置编码外推性要好一些，旋转位置编码也是基于正余弦三角式位置编码改进融入相对位置信息，但是正余弦三角式位置编码外推性缺点也很明显，
看起来是不需要训练可以直接推演无限长度位置编码，但是忽略了一点就是周期性函数必须进行位置衰减，到远处的位置信息趋于直线震荡，基本很难有位置信息区分了，
所以外推性比训练式的好不了多少，旋转位置编码基于此改进的自然也是如此。

Alibi 相当于在k和q向量内积上加入分数上的偏置，来体现出来位置差异性，针对于远距离衰减问题，则是通过softmax函数特性进行差异软放大，
将token之间的位置差异性拉大，避免远距离时被衰减无限接近于0，因为直接作用在attention分数上，拉大远距离内积值，
在训练的时候带来的位置差异性减少的问题会大大缓解，从而获得更远距离的外推性能。


要建立元数据过滤单元，不是一上来就全文检索，要有更精细化的索引，根据查询需求先做一遍过滤，比如时间、内容源等等；要建立全文处理单元，
解决由于切割带来的信息损耗，需要从离线、在线两部分同时考虑，离线预计算覆盖高频需求，在线覆盖长尾需求；要建立数值计算单元，
弥补大模型在做数学题上的缺陷，并且补充足够的金融行业计算公式或企业自定义计算公式；要建立数据库查询单元，区别于“数值计算”，
这里主要是指NL2Sql，有些信息查询需要走数据库而不仅仅是文章内容；要建立意图澄清单元，我们允许用户发起五花八门的查询请求，
但当查询需求不明确时，系统要有能力帮助用户改进查询语言；
