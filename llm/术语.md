1.预训练（pre-train）是通过大量无标注的语言文本进行语言模型的训练，得到一套模型参数，利用这套参数对模型进行初始化，再根据具体任务在现有语言模型的基础上进行精调。

2.微调（FineTuning）：是一种在自然语言处理中使用的技术，用于将预训练的语言模型适应于特定任务或领域。Fine-tuning的基本思想是采用已经在大量文本上进行过训练的预训练语言模型，然后在小规模的任务特定文本上继续训练它。在大语言模型的领域, 指令学习基本等同于fine-tuning。

Fine-tuning的类别包括：
全参数量微调(传统的SFT)：训练过程 改写全部参数, 利于学习新知识, 但会对模型之前已有的知识造成冲击.
局部参数调整：
P-tuning：仅改写一层, 训练时长得以大大缩短。
微调步数影响：模型参数较小时，步数越多，效果越好。同样随着模型参数达到一定规模，zero shot 也能取得不错效果。
当参数达到100亿规模与全参数微调方式效果无异。
本质上更接近于激发模型现有知识
LoRA
参数量较全参数微调（Fine-Tuning）显著降低，参数量和现有高效参数微调方法持平或更低。
性能优于其它参数高效微调方法，和全参数微调（Fine-Tuning）基本持平甚至更高。
3.指令微调（Instruction fine-tuning，IFT）指令是指用户传入的目的明确的输入文本，针对任务集合而形成的。指令微调的目的是激发语言模型理解任务的能力，并将这种理解能力泛化到未知任务上。简单来说就是学会听人话，说人话。

4.思维链（Chain-of-Thought，CoT）思维链的主要思想是通过向LLMs的学习样例中加入思维的推理过程，让大语言模型在生成答案时也显示推理过程。这种推理的过程往往会引导出更准确的结果。思维链把一个多步推理问题分解出多个中间步骤，让 LLMs 更加具有可解释。---让大语言模型将一个问题拆解成多个步骤，一步一步分析，逐步得出正确答案。需指出，针对复杂问题，LLM直接给出错误答案的概率比较高。思维链可以看成一种指令微调。

5.涌现（Emergence）指的是当模型参数规模未能达到某个阀值时，模型基本不具备解决此类任务的任何能力，体现为其性能和随机选择答案效果相当，例如常识推理、问答、翻译、数学、摘要等。但是当模型规模跨过阀值，LLM模型对此类任务的效果就出现突然的性能增长。也就是说，模型规模是解锁LLM新能力的关键，随着模型规模越来越大，会逐渐解锁LLM越来越多的新能力。---许多小实体相互作用产生了大实体（模型规模达到一定阈值后），大实体展现了组成它的小实体所不具备的特性。

6.Scaling Law：尺度定律：指的是模型的能力与参数量、数据量、训练量的渐进关系。以往研究的实验结果表明，神经网络的尺度定律多数呈现”幂律（Power law）”的形式。Chinchilla文章指出，给定固定计算量 ，模型大小和训练的tokens数量应该按相同比例缩放，tokens数量（Trillion）和模型规模（Billion）呈20 : 1的关系。

7.自洽方法（Self-consistency）尽管LLMs在一系列NLP任务中取得了显著的成功，但它们的推理能力往往不足，仅靠扩大模型规模不能解决这个问题。 基于此，有文章提出了思维提示链（chain of thought prompting），提示语言模型生成一系列短句，这些短句模仿一个人在解决推理任务时可能采用的推理过程。 但是，复杂的推理任务通常有多个能得到正确答案的推理路径，自洽方法就是通过思维提示链从语言模型中采样一组不同的推理路径，然后返回其中最自洽的答案。 其原理来自人类的一个突出特征是思维方式不同。 人们会很自然地假设，在需要深思熟虑的任务中，可能有几种解决方法，所有这些方法都会得出相同的正确答案。 因此，可以通过从语言模型解码器采样以在语言模型中模拟这一过程。

具体的方法
首先，使用一组手动编写的思维链示例对语言模型进行提示；
接着，从语言模型的解码器中采样一组候选输出，生成一组不同的候选推理路径；
最后，通过在生成的答案中选择最自洽的答案来集成结果。
8.pan class="nolink">泛化(Generalization) ：模型的泛化能力是指一个模型在面对新的、未见过的数据时，能够正确理解和预测这些数据的能力。--模型可应用到其他场景或领域，通常采用迁移学习、微调等手段实现泛化。

9.幻觉（hallucinations）指的是聊天机器人完全捏造信息，并表现成滔滔不绝讲述事实的样子来回应用户的提示语问题。

解决办法：
增加数据多样性，通过增加训练数据集的多样性，增加AI模型的泛化能力，减少对特定数据集的依赖，从而减少幻觉的出现。
改进模型架构，通过改进AI模型的架构，例如使用更加负责的神经网络结构，增加模型的深度或宽度等，提高模型的性能和泛化能力，减少幻觉出现
引入对抗性训练，对抗性训练是通过向模型输入故意制造的错误样本，以提高模型鲁棒性，帮助模型更好地处理输入异常，确保决策的正确性。
增加人工干预，对于一些关键的决策，引入人力专家的判断，确保决策的正确性。