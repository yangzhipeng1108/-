https://zhuanlan.zhihu.com/p/666414155

IR步骤可以被划分成query改写、检索、重排序和reader四个阶段，如上图所示，这四个阶段都可以应用LLM。

query改写：query改写通过修改或重写用户的输入query，可以改善query的准确度和表示能力。这一步骤的主流方法是query扩写。

检索：主要用于查询doc的召回。检索阶段早期使用的词袋模型鲁棒、高效，随着神经网络IR的兴起，
流行做法变成了抽查询query和候选doc中提取高维稠密表示并计算内积作为相关性打分的方式。

重排序：检索阶段平衡了效果和效率，重排序阶段主要保障检索的质量，会采用比传统向量内积更复杂的方法，以得到更好的排序效果。
此外，重排序阶段还需要设计特定的策略，来满足不同用户的需求，比如个性化和多样性需求等。

reader：reader是随着大预言模型快速发展起来的一个模块，它实时理解用户意图，并根据检索结果动态生成响应。
相较于传统的给用户呈现一个候选文档列表的方式，reader模块以人类获取信息的方式组织检索结果。
为了提高结果的可信度，将参考文献集成到生成的结果中是该模块的一种有效技术。

重写阶段
两个检索范式
Ad-hoc检索
LLMs用于Ad-hoc检索阶段的方式：输入查询query，LLM生成doc，生成的doc和query组成新的query输入的查询系统中进行信息检索。这样做是因为生成doc中的包含的额外细节信息。

对话式搜索

对话式搜索有助于澄清用户的检索意图。LLMs用于对话式搜索主要是借助大模型的两个能力：
LLM具有强大的上下文理解能力，使其能够更好地理解用户与系统之间多回合对话的文本中用户的搜索意图；
LLM具有强大的生成能力，可以模拟用户和系统之间的对话，从而促进更稳健的搜索意图建模。

使用领域特定数据增强LLM的能力

LLM可能生成幻觉或者无关的query，引入领域数据来解决这类问题。
做法包括两种
将query和文档合并作为prompt输入LLM；
结合LLM生成的相关性反馈（GRF）和伪相关反馈（PRF）
GRF能提供第一遍检索不包含的信息；
PRF将查询限制为包含在目标语料库内的信息。

主流方法有三种：

最流行的方法是prompt，设计特定的prompt或输入结构，让语言模型生成预期的输出。模型结构不变，模型参数不变。
在特定领域微调LLMs；模型结构不变，模型参数变化。
知识蒸馏；模型参数和结构都发生变化，用小模型近似大模型的效果。
prompt方法

zero-shot prompt-零样本。只依赖模型自身对输入query的理解能力生成文本，是一种简单有效的query重写方法。
few-shot prompt-少样本。即上下文学习（ in-context learnin），通过输入有限的示例，让模型具有适应特定任务或场景的能力。
Chain-of-thought prompt-思维链。给模型提供一系列指令或部分输出，以让模型做更深入的思考。对话式搜索中，query重新是通过多轮对话完成的，ad-hoc搜索因为只有一轮输入query，只能用简单粗糙的方式实现思维链prompt。

检索阶段
LLM用检索阶段有两种方法：用LLM生成检索结果；用LLM增强模型结构。
LLM生成检索结果
第一个视角围绕着搜索数据优化方法，这些方法专注于重新制定输入查询，以精确地呈现用户意图。
第二个视角涉及训练数据扩充方法，该方法利用LLM的生成能力来扩充密集检索模型的训练数据，特别是在零样本或少样本场景中。

训练数据扩展
检索模型是监督学习模型，需要训练数据（query和doc）和label（doc和query是否相关），因为doc一般是一个相对固定的集合，
故数据增强从doc中生成伪query和生成label两个方向考虑。

用LMM增强模型结构
LLM具有很好的文本编码和解码能力，可以用于query和doc的理解。LMM增强检索模型结构有两种做法：基于编码器的检索模型和生成式检索模型。

基于编码器的检索模型

将LLM用于检索任务中的文本编码器；
设计任务相关的prompt，比如引入问题、领域、意图等信息。
生成式检索模型

传统的IR系统包括“index-retrieval-rank” 三个阶段，生成式检索模型用一个单一的模型针对查询query直接生成doc。做法包括微调大模型和prompt大模型两种。
DSI是一个用检索数据对预训练的T5模型进行微调的方法，该方法对查询query进行编码，并对doc进行解码以得到查询结果。为了保证得到的doc真实有效，DSI使用多有的doc的ID构建字典树，并使用beam search进行解码。
prompt大模型是直接让大模型生成针对输入query的文档url。LLM-URL模型是本方向的一个工作，模型用GPT-3 text-davinci-003模型生成候选url，然后设计正则化表示从候选中提取有效的url。


LLM因为强大的语言理解和生成能力，可以被应用在IR系统的多个模块中：

在查询重写领域，LLM已经证明了它们在理解歧义或多方面查询方面的有效性，提高了意图识别的准确性。
在检索方面，LLM通过在查询和文档之间实现更细微的匹配，同时考虑上下文，提高了检索的准确性。
在重新排序领域中，LLM增强模型在重新排序结果时考虑了更细粒度的语言细微差别。
IR系统中阅读器模块的用途代表着生成全面响应而不仅仅是文档列表的重要一步。LLMs与IR系统的集成带来了用户参与信息和知识的根本变化。